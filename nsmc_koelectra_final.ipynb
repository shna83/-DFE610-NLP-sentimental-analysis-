{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nsmc_koelectra_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shna83/-DFE610-NLP-sentimental-analysis-/blob/DFE61000%5DNLP-FOR-DIGITAL-FINANCE-ENGINEERING/nsmc_koelectra_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggmrLSeTFIk3"
      },
      "source": [
        "Data download, library install/import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpmqOl-API_j",
        "outputId": "58267182-ca7e-40c6-b4ff-3f7af6ab1612"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BoASBZrPQ7C"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import torch\r\n",
        "\r\n",
        "from transformers import ElectraTokenizer\r\n",
        "from transformers import ElectraForSequenceClassification, AdamW\r\n",
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import time\r\n",
        "import datetime\r\n",
        "from tqdm import tqdm\r\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u95SY5oJPR96",
        "outputId": "a4497bd1-1c50-4f2f-a795-41f48914f531"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jULIv5nPcLI",
        "outputId": "a655ae61-3f91-48c0-e086-966a7c132c2f"
      },
      "source": [
        "# 네이버 영화 감성분석 데이터 다운로드\r\n",
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'nsmc' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gy_2Z-HPeqq",
        "outputId": "1dfe86c0-2848-405d-fcdf-51a0edee707a"
      },
      "source": [
        "os.listdir('nsmc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['synopses.json',\n",
              " 'code',\n",
              " 'README.md',\n",
              " '.git',\n",
              " 'raw',\n",
              " 'ratings_test.txt',\n",
              " 'ratings.txt',\n",
              " 'ratings_train.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzm3msy8PinT"
      },
      "source": [
        "train = pd.read_table(\"nsmc/\"+\"ratings_train.txt\")\r\n",
        "test = pd.read_table(\"nsmc/\"+\"ratings_test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "rKAnq1jFPnrV",
        "outputId": "b8357d96-45be-4d87-9b34-3e8e55eb3281"
      },
      "source": [
        "train[1:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5403919</td>\n",
              "      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7797314</td>\n",
              "      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9443947</td>\n",
              "      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7156791</td>\n",
              "      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5912145</td>\n",
              "      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
              "5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n",
              "6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n",
              "7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n",
              "8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n",
              "9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzUqi_f8E98s"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJiq4O0yPp8p"
      },
      "source": [
        "MAX_LEN = 128\r\n",
        "\r\n",
        "def getInputs(dataset):\r\n",
        "  data = dataset.copy(deep=True)\r\n",
        "\r\n",
        "  if 'document' in data.columns:\r\n",
        "    sentences = data['document']\r\n",
        "  else:\r\n",
        "    sentences = data['Sentence']\r\n",
        "\r\n",
        "  sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\r\n",
        "  \r\n",
        "  tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v2-discriminator\", do_lower_case=False)\r\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "\r\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "  attention_masks = []\r\n",
        "  for seq in input_ids:\r\n",
        "      seq_mask = [float(i>0) for i in seq]\r\n",
        "      attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtJ8Gzvxwgmc"
      },
      "source": [
        "def getIndex(dataset):\r\n",
        "  data = dataset.copy(deep = True)\r\n",
        "  input_index = data.index.tolist()\r\n",
        "  return torch.tensor(input_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYPWtJcHQRtv"
      },
      "source": [
        "train_inputs, train_masks = getInputs(train)\r\n",
        "test_inputs, test_masks = getInputs(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6454FfyZnQDb"
      },
      "source": [
        "train_labels= train['label'].values\r\n",
        "test_labels= test['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4d3A-y8QqdL"
      },
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\r\n",
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "\r\n",
        "validation_inputs = torch.tensor(test_inputs)\r\n",
        "validation_labels = torch.tensor(test_labels)\r\n",
        "validation_masks = torch.tensor(test_masks)\t\t\t\r\n",
        "\r\n",
        "#test_index = getIndex(test)\r\n",
        "#test_inputs = torch.tensor(test_inputs)\r\n",
        "#test_masks = torch.tensor(test_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1-cM-bjQymC"
      },
      "source": [
        "batch_size = 10\r\n",
        "\r\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n",
        "validation_sampler = SequentialSampler(validation_data)\r\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "#test_data = TensorDataset(test_index, test_inputs, test_masks)\r\n",
        "#test_sampler = RandomSampler(test_data)\r\n",
        "#test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY7w3jNwF2N2"
      },
      "source": [
        "modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPXNdNedRCdu",
        "outputId": "f96f1027-b047-4651-b564-a9e3d5c98faa"
      },
      "source": [
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhbgEBs6ytKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce582eb9-e060-4711-e083-6bd40188dc7c"
      },
      "source": [
        "#KoELECTRA 모델 생성\r\n",
        "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v2-discriminator\", num_labels = 2)\r\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v2-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v2-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(32200, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7h8Ki5ARFtq"
      },
      "source": [
        "# 옵티마이저 설정\r\n",
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 3e-5, # 학습률\r\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\r\n",
        "                )\r\n",
        "\r\n",
        "# 에폭수\r\n",
        "epochs = 2\r\n",
        "\r\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0,\r\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuHwzMhzRLwC"
      },
      "source": [
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    \r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lln7vT5tRROa"
      },
      "source": [
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z6bdvlORWJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810a8594-d0f6-476c-ba15-cba351bdb4be"
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\r\n",
        "seed_val = 42\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "# 그래디언트 초기화\r\n",
        "model.zero_grad()\r\n",
        "\r\n",
        "# 에폭만큼 반복\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # 시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 로스 초기화\r\n",
        "    total_loss = 0\r\n",
        "\r\n",
        "    # 훈련모드로 변경\r\n",
        "    model.train()\r\n",
        "        \r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "        # 경과 정보 표시\r\n",
        "        if step % 500 == 0 and not step == 0:\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "        # Forward 수행                \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask, \r\n",
        "                        labels=b_labels)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        loss = outputs[0]\r\n",
        "\r\n",
        "        # 총 로스 계산\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        # Backward 수행으로 그래디언트 계산\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # 그래디언트 클리핑\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # 스케줄러로 학습률 감소\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "        # 그래디언트 초기화\r\n",
        "        model.zero_grad()\r\n",
        "\r\n",
        "    # 평균 로스 계산\r\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    #시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 평가모드로 변경\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 변수 초기화\r\n",
        "    eval_loss, eval_accuracy = 0, 0\r\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for batch in validation_dataloader:\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "        \r\n",
        "        # 그래디언트 계산 안함\r\n",
        "        with torch.no_grad():     \r\n",
        "            # Forward 수행\r\n",
        "            outputs = model(b_input_ids, \r\n",
        "                            token_type_ids=None, \r\n",
        "                            attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        logits = outputs[0]\r\n",
        "\r\n",
        "        # CPU로 데이터 이동\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "        \r\n",
        "        # 출력 로직과 라벨을 비교하여 정확도 계산\r\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "        eval_accuracy += tmp_eval_accuracy\r\n",
        "        nb_eval_steps += 1\r\n",
        "\r\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch   500  of  15,000.    Elapsed: 0:02:06.\n",
            "  Batch 1,000  of  15,000.    Elapsed: 0:04:13.\n",
            "  Batch 1,500  of  15,000.    Elapsed: 0:06:20.\n",
            "  Batch 2,000  of  15,000.    Elapsed: 0:08:27.\n",
            "  Batch 2,500  of  15,000.    Elapsed: 0:10:34.\n",
            "  Batch 3,000  of  15,000.    Elapsed: 0:12:40.\n",
            "  Batch 3,500  of  15,000.    Elapsed: 0:14:47.\n",
            "  Batch 4,000  of  15,000.    Elapsed: 0:16:53.\n",
            "  Batch 4,500  of  15,000.    Elapsed: 0:18:59.\n",
            "  Batch 5,000  of  15,000.    Elapsed: 0:21:06.\n",
            "  Batch 5,500  of  15,000.    Elapsed: 0:23:13.\n",
            "  Batch 6,000  of  15,000.    Elapsed: 0:25:20.\n",
            "  Batch 6,500  of  15,000.    Elapsed: 0:27:26.\n",
            "  Batch 7,000  of  15,000.    Elapsed: 0:29:33.\n",
            "  Batch 7,500  of  15,000.    Elapsed: 0:31:40.\n",
            "  Batch 8,000  of  15,000.    Elapsed: 0:33:46.\n",
            "  Batch 8,500  of  15,000.    Elapsed: 0:35:52.\n",
            "  Batch 9,000  of  15,000.    Elapsed: 0:37:59.\n",
            "  Batch 9,500  of  15,000.    Elapsed: 0:40:05.\n",
            "  Batch 10,000  of  15,000.    Elapsed: 0:42:11.\n",
            "  Batch 10,500  of  15,000.    Elapsed: 0:44:18.\n",
            "  Batch 11,000  of  15,000.    Elapsed: 0:46:24.\n",
            "  Batch 11,500  of  15,000.    Elapsed: 0:48:31.\n",
            "  Batch 12,000  of  15,000.    Elapsed: 0:50:37.\n",
            "  Batch 12,500  of  15,000.    Elapsed: 0:52:44.\n",
            "  Batch 13,000  of  15,000.    Elapsed: 0:54:50.\n",
            "  Batch 13,500  of  15,000.    Elapsed: 0:56:56.\n",
            "  Batch 14,000  of  15,000.    Elapsed: 0:59:03.\n",
            "  Batch 14,500  of  15,000.    Elapsed: 1:01:10.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 1:03:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:06:36\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch   500  of  15,000.    Elapsed: 0:02:06.\n",
            "  Batch 1,000  of  15,000.    Elapsed: 0:04:13.\n",
            "  Batch 1,500  of  15,000.    Elapsed: 0:06:19.\n",
            "  Batch 2,000  of  15,000.    Elapsed: 0:08:26.\n",
            "  Batch 2,500  of  15,000.    Elapsed: 0:10:32.\n",
            "  Batch 3,000  of  15,000.    Elapsed: 0:12:39.\n",
            "  Batch 3,500  of  15,000.    Elapsed: 0:14:46.\n",
            "  Batch 4,000  of  15,000.    Elapsed: 0:16:52.\n",
            "  Batch 4,500  of  15,000.    Elapsed: 0:18:59.\n",
            "  Batch 5,000  of  15,000.    Elapsed: 0:21:06.\n",
            "  Batch 5,500  of  15,000.    Elapsed: 0:23:12.\n",
            "  Batch 6,000  of  15,000.    Elapsed: 0:25:19.\n",
            "  Batch 6,500  of  15,000.    Elapsed: 0:27:26.\n",
            "  Batch 7,000  of  15,000.    Elapsed: 0:29:32.\n",
            "  Batch 7,500  of  15,000.    Elapsed: 0:31:39.\n",
            "  Batch 8,000  of  15,000.    Elapsed: 0:33:45.\n",
            "  Batch 8,500  of  15,000.    Elapsed: 0:35:52.\n",
            "  Batch 9,000  of  15,000.    Elapsed: 0:37:58.\n",
            "  Batch 9,500  of  15,000.    Elapsed: 0:40:04.\n",
            "  Batch 10,000  of  15,000.    Elapsed: 0:42:11.\n",
            "  Batch 10,500  of  15,000.    Elapsed: 0:44:16.\n",
            "  Batch 11,000  of  15,000.    Elapsed: 0:46:22.\n",
            "  Batch 11,500  of  15,000.    Elapsed: 0:48:29.\n",
            "  Batch 12,000  of  15,000.    Elapsed: 0:50:35.\n",
            "  Batch 12,500  of  15,000.    Elapsed: 0:52:41.\n",
            "  Batch 13,000  of  15,000.    Elapsed: 0:54:48.\n",
            "  Batch 13,500  of  15,000.    Elapsed: 0:56:54.\n",
            "  Batch 14,000  of  15,000.    Elapsed: 0:59:00.\n",
            "  Batch 14,500  of  15,000.    Elapsed: 1:01:07.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 1:03:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation took: 0:06:36\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VCxZFFiSOA7"
      },
      "source": [
        "#model.save(\"/content/gdrive/MyDrive/nsmc_koelectra.h5\")\r\n",
        "torch.save(model.state_dict(), \"naver_electra.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AfChFiXD7YQ",
        "outputId": "cf11952f-df69-4d2f-f7e4-3b0c5c1b04eb"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wABg8jvKGfWc"
      },
      "source": [
        "model accuracy test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_xIGkZxQBv2"
      },
      "source": [
        "# 캐글데이터 불러오기 \r\n",
        "test_data = pd.read_csv(\"/content/gdrive/My Drive/ko_data.csv\",encoding='cp949')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cel-GtaAolPb"
      },
      "source": [
        "test_inputs, test_masks = getInputs(test_data)\r\n",
        "test_index = getIndex(test_data)\r\n",
        "test_inputs = torch.tensor(test_inputs)\r\n",
        "test_masks = torch.tensor(test_masks)\r\n",
        "test_data_final = TensorDataset(test_index, test_inputs, test_masks)\r\n",
        "test_sampler = RandomSampler(test_data)\r\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56lxFlBjSv7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42477171-2152-469c-97df-6e7b48641123"
      },
      "source": [
        "tmp_test_dataloader = DataLoader(test_data_final, sampler=test_sampler, batch_size=1)\r\n",
        "test_result = test_data.copy(deep = True)\r\n",
        "test_result['Predicted'] = 'default'\r\n",
        "classes = [0, 1]\r\n",
        "\r\n",
        "#시작 시간 설정\r\n",
        "t0 = time.time()\r\n",
        "\r\n",
        "# 평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "for step, batch in enumerate(tmp_test_dataloader):\r\n",
        "    # 경과 정보 표시\r\n",
        "    if step % 100 == 0 and not step == 0:\r\n",
        "        elapsed = format_time(time.time() - t0)\r\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\r\n",
        "\r\n",
        "    # 배치를 GPU에 넣음\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    \r\n",
        "    # 배치에서 데이터 추출\r\n",
        "    b_index, b_input_ids, b_input_mask = batch\r\n",
        "    \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "    \r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    idx = b_index.item()\r\n",
        "    test_result['Predicted'][idx] = classes[np.argmax(logits)]\r\n",
        "    \r\n",
        "\r\n",
        "    nb_eval_steps += 1\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,119.    Elapsed: 0:00:01.\n",
            "  Batch   200  of  1,119.    Elapsed: 0:00:03.\n",
            "  Batch   300  of  1,119.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,119.    Elapsed: 0:00:05.\n",
            "  Batch   500  of  1,119.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,119.    Elapsed: 0:00:08.\n",
            "  Batch   700  of  1,119.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,119.    Elapsed: 0:00:11.\n",
            "  Batch   900  of  1,119.    Elapsed: 0:00:12.\n",
            "  Batch 1,000  of  1,119.    Elapsed: 0:00:14.\n",
            "  Batch 1,100  of  1,119.    Elapsed: 0:00:15.\n",
            "  Batch 1,200  of  1,119.    Elapsed: 0:00:16.\n",
            "  Batch 1,300  of  1,119.    Elapsed: 0:00:18.\n",
            "  Batch 1,400  of  1,119.    Elapsed: 0:00:19.\n",
            "  Batch 1,500  of  1,119.    Elapsed: 0:00:20.\n",
            "  Batch 1,600  of  1,119.    Elapsed: 0:00:22.\n",
            "  Batch 1,700  of  1,119.    Elapsed: 0:00:23.\n",
            "  Batch 1,800  of  1,119.    Elapsed: 0:00:24.\n",
            "  Batch 1,900  of  1,119.    Elapsed: 0:00:26.\n",
            "  Batch 2,000  of  1,119.    Elapsed: 0:00:27.\n",
            "  Batch 2,100  of  1,119.    Elapsed: 0:00:29.\n",
            "  Batch 2,200  of  1,119.    Elapsed: 0:00:30.\n",
            "  Batch 2,300  of  1,119.    Elapsed: 0:00:31.\n",
            "  Batch 2,400  of  1,119.    Elapsed: 0:00:33.\n",
            "  Batch 2,500  of  1,119.    Elapsed: 0:00:34.\n",
            "  Batch 2,600  of  1,119.    Elapsed: 0:00:35.\n",
            "  Batch 2,700  of  1,119.    Elapsed: 0:00:37.\n",
            "  Batch 2,800  of  1,119.    Elapsed: 0:00:38.\n",
            "  Batch 2,900  of  1,119.    Elapsed: 0:00:39.\n",
            "  Batch 3,000  of  1,119.    Elapsed: 0:00:41.\n",
            "  Batch 3,100  of  1,119.    Elapsed: 0:00:42.\n",
            "  Batch 3,200  of  1,119.    Elapsed: 0:00:43.\n",
            "  Batch 3,300  of  1,119.    Elapsed: 0:00:44.\n",
            "  Batch 3,400  of  1,119.    Elapsed: 0:00:46.\n",
            "  Batch 3,500  of  1,119.    Elapsed: 0:00:47.\n",
            "  Batch 3,600  of  1,119.    Elapsed: 0:00:48.\n",
            "  Batch 3,700  of  1,119.    Elapsed: 0:00:50.\n",
            "  Batch 3,800  of  1,119.    Elapsed: 0:00:51.\n",
            "  Batch 3,900  of  1,119.    Elapsed: 0:00:52.\n",
            "  Batch 4,000  of  1,119.    Elapsed: 0:00:54.\n",
            "  Batch 4,100  of  1,119.    Elapsed: 0:00:55.\n",
            "  Batch 4,200  of  1,119.    Elapsed: 0:00:56.\n",
            "  Batch 4,300  of  1,119.    Elapsed: 0:00:57.\n",
            "  Batch 4,400  of  1,119.    Elapsed: 0:00:59.\n",
            "  Batch 4,500  of  1,119.    Elapsed: 0:01:00.\n",
            "  Batch 4,600  of  1,119.    Elapsed: 0:01:01.\n",
            "  Batch 4,700  of  1,119.    Elapsed: 0:01:03.\n",
            "  Batch 4,800  of  1,119.    Elapsed: 0:01:04.\n",
            "  Batch 4,900  of  1,119.    Elapsed: 0:01:05.\n",
            "  Batch 5,000  of  1,119.    Elapsed: 0:01:07.\n",
            "  Batch 5,100  of  1,119.    Elapsed: 0:01:08.\n",
            "  Batch 5,200  of  1,119.    Elapsed: 0:01:09.\n",
            "  Batch 5,300  of  1,119.    Elapsed: 0:01:10.\n",
            "  Batch 5,400  of  1,119.    Elapsed: 0:01:12.\n",
            "  Batch 5,500  of  1,119.    Elapsed: 0:01:13.\n",
            "  Batch 5,600  of  1,119.    Elapsed: 0:01:14.\n",
            "  Batch 5,700  of  1,119.    Elapsed: 0:01:16.\n",
            "  Batch 5,800  of  1,119.    Elapsed: 0:01:17.\n",
            "  Batch 5,900  of  1,119.    Elapsed: 0:01:18.\n",
            "  Batch 6,000  of  1,119.    Elapsed: 0:01:20.\n",
            "  Batch 6,100  of  1,119.    Elapsed: 0:01:21.\n",
            "  Batch 6,200  of  1,119.    Elapsed: 0:01:22.\n",
            "  Batch 6,300  of  1,119.    Elapsed: 0:01:23.\n",
            "  Batch 6,400  of  1,119.    Elapsed: 0:01:25.\n",
            "  Batch 6,500  of  1,119.    Elapsed: 0:01:26.\n",
            "  Batch 6,600  of  1,119.    Elapsed: 0:01:27.\n",
            "  Batch 6,700  of  1,119.    Elapsed: 0:01:29.\n",
            "  Batch 6,800  of  1,119.    Elapsed: 0:01:30.\n",
            "  Batch 6,900  of  1,119.    Elapsed: 0:01:31.\n",
            "  Batch 7,000  of  1,119.    Elapsed: 0:01:32.\n",
            "  Batch 7,100  of  1,119.    Elapsed: 0:01:34.\n",
            "  Batch 7,200  of  1,119.    Elapsed: 0:01:35.\n",
            "  Batch 7,300  of  1,119.    Elapsed: 0:01:36.\n",
            "  Batch 7,400  of  1,119.    Elapsed: 0:01:38.\n",
            "  Batch 7,500  of  1,119.    Elapsed: 0:01:39.\n",
            "  Batch 7,600  of  1,119.    Elapsed: 0:01:40.\n",
            "  Batch 7,700  of  1,119.    Elapsed: 0:01:42.\n",
            "  Batch 7,800  of  1,119.    Elapsed: 0:01:43.\n",
            "  Batch 7,900  of  1,119.    Elapsed: 0:01:44.\n",
            "  Batch 8,000  of  1,119.    Elapsed: 0:01:45.\n",
            "  Batch 8,100  of  1,119.    Elapsed: 0:01:47.\n",
            "  Batch 8,200  of  1,119.    Elapsed: 0:01:48.\n",
            "  Batch 8,300  of  1,119.    Elapsed: 0:01:49.\n",
            "  Batch 8,400  of  1,119.    Elapsed: 0:01:51.\n",
            "  Batch 8,500  of  1,119.    Elapsed: 0:01:52.\n",
            "  Batch 8,600  of  1,119.    Elapsed: 0:01:53.\n",
            "  Batch 8,700  of  1,119.    Elapsed: 0:01:54.\n",
            "  Batch 8,800  of  1,119.    Elapsed: 0:01:56.\n",
            "  Batch 8,900  of  1,119.    Elapsed: 0:01:57.\n",
            "  Batch 9,000  of  1,119.    Elapsed: 0:01:58.\n",
            "  Batch 9,100  of  1,119.    Elapsed: 0:01:59.\n",
            "  Batch 9,200  of  1,119.    Elapsed: 0:02:01.\n",
            "  Batch 9,300  of  1,119.    Elapsed: 0:02:02.\n",
            "  Batch 9,400  of  1,119.    Elapsed: 0:02:03.\n",
            "  Batch 9,500  of  1,119.    Elapsed: 0:02:05.\n",
            "  Batch 9,600  of  1,119.    Elapsed: 0:02:06.\n",
            "  Batch 9,700  of  1,119.    Elapsed: 0:02:07.\n",
            "  Batch 9,800  of  1,119.    Elapsed: 0:02:08.\n",
            "  Batch 9,900  of  1,119.    Elapsed: 0:02:10.\n",
            "  Batch 10,000  of  1,119.    Elapsed: 0:02:11.\n",
            "  Batch 10,100  of  1,119.    Elapsed: 0:02:12.\n",
            "  Batch 10,200  of  1,119.    Elapsed: 0:02:13.\n",
            "  Batch 10,300  of  1,119.    Elapsed: 0:02:15.\n",
            "  Batch 10,400  of  1,119.    Elapsed: 0:02:16.\n",
            "  Batch 10,500  of  1,119.    Elapsed: 0:02:17.\n",
            "  Batch 10,600  of  1,119.    Elapsed: 0:02:19.\n",
            "  Batch 10,700  of  1,119.    Elapsed: 0:02:20.\n",
            "  Batch 10,800  of  1,119.    Elapsed: 0:02:21.\n",
            "  Batch 10,900  of  1,119.    Elapsed: 0:02:22.\n",
            "  Batch 11,000  of  1,119.    Elapsed: 0:02:24.\n",
            "  Batch 11,100  of  1,119.    Elapsed: 0:02:25.\n",
            "\n",
            "Test took: 0:02:26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "3mAJGiHYTwBF",
        "outputId": "76a43aa0-5049-4244-8443-fbf1202ee79a"
      },
      "source": [
        "test_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>정말 많이 울었던 영화입니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>시간 낭비예요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>이걸 영화로 만드는 거야?얼마나 가는지 보자.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11182</th>\n",
              "      <td>11182</td>\n",
              "      <td>이 영화를 커플에게 추천합니다. 영화관에 가다보면 평생 잊지 못할 추억이 하나 생길...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11183</th>\n",
              "      <td>11183</td>\n",
              "      <td>심심__ 그냥 한효주 cf</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11184</th>\n",
              "      <td>11184</td>\n",
              "      <td>공감해서 눈물나는 영화. 안 보신분들이 전부 제가 울었다고 하면 의아해하실텐데 보면...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11185</th>\n",
              "      <td>11185</td>\n",
              "      <td>오토바이 신은 최고네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11186</th>\n",
              "      <td>11186</td>\n",
              "      <td>개병헌 쓰면 엉망이 된다ㅋㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11187 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id                                           Sentence Predicted\n",
              "0          0                                   정말 많이 울었던 영화입니다.         1\n",
              "1          1                                           시간 낭비예요.         0\n",
              "2          2             포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.         0\n",
              "3          3               지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!         1\n",
              "4          4                          이걸 영화로 만드는 거야?얼마나 가는지 보자.         0\n",
              "...      ...                                                ...       ...\n",
              "11182  11182  이 영화를 커플에게 추천합니다. 영화관에 가다보면 평생 잊지 못할 추억이 하나 생길...         1\n",
              "11183  11183                                     심심__ 그냥 한효주 cf         0\n",
              "11184  11184  공감해서 눈물나는 영화. 안 보신분들이 전부 제가 울었다고 하면 의아해하실텐데 보면...         1\n",
              "11185  11185                                      오토바이 신은 최고네요.         0\n",
              "11186  11186                                   개병헌 쓰면 엉망이 된다ㅋㅋㅋ         0\n",
              "\n",
              "[11187 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXYtpDy4ooHn"
      },
      "source": [
        "test_result[[\"Id\",\"Predicted\"]].to_csv(\"/content/gdrive/My Drive/nsmc_koelectra_v2.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_RphLg9c9Dl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}